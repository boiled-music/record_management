from flask import Flask, render_template, request, send_file
import mysql.connector
import csv
import io

app = Flask(__name__)

# âœ… MariaDB ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    return mysql.connector.connect(
        host='localhost',
        user='root',
        password='a12345678!',  # ìì‹ ì˜ MariaDB ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
        database='record_management_db',
        charset='utf8mb4',
        collation='utf8mb4_general_ci'  # Collation ëª…ì‹œ
    )

# âœ… ë³´ì¡´ê¸°ê°„ ë³€í™˜ ë§¤í•‘
PRESERVATION_PERIOD_MAP = {
    45: "ì˜êµ¬",
    40: "ì¤€ì˜êµ¬",
    30: "30ë…„",
    10: "10ë…„",
    5: "5ë…„",
    3: "3ë…„",
    1: "1ë…„",
    0: "ë¯¸í™•ì¸"
}

# âœ… ë°˜ì¶œ ìˆœìœ„ ë³€í™˜ ë§¤í•‘
RETRIEVAL_PRIORITY_MAP = {
    1: "1ìˆœìœ„",
    2: "2ìˆœìœ„",
    3: "3ìˆœìœ„",
    0: "ë¯¸í™•ì¸"
}

# âœ… ë©”ì¸ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€ (í†µê³„ í¬í•¨)
@app.route('/')
def main_dashboard():
    conn = get_db_connection()
    cursor = conn.cursor(dictionary=True)

    # ë³´ì¡´ê¸°ê°„ë³„ í†µê³„ ì´ˆê¸°í™”
    storage_data = {
        "ì œ1ê¸°ë¡ê´€": {p: 0 for p in PRESERVATION_PERIOD_MAP.values()},
        "ì œ2ê¸°ë¡ê´€": {p: 0 for p in PRESERVATION_PERIOD_MAP.values()},
        "í–‰ì •ë°•ë¬¼ê´€": {p: 0 for p in PRESERVATION_PERIOD_MAP.values()}
    }
    total_sums = {p: 0 for p in PRESERVATION_PERIOD_MAP.values()}
    total_sums["í•©ê³„"] = 0

    cursor.execute("""
        SELECT storage_location, preservation_period, COUNT(*) AS total
        FROM documents
        WHERE storage_location IN ('ì œ1ê¸°ë¡ê´€', 'ì œ2ê¸°ë¡ê´€', 'í–‰ì •ë°•ë¬¼ê´€')
        GROUP BY storage_location, preservation_period
    """)
    location_totals = {"ì œ1ê¸°ë¡ê´€": 0, "ì œ2ê¸°ë¡ê´€": 0, "í–‰ì •ë°•ë¬¼ê´€": 0}
    for row in cursor.fetchall():
        location = row["storage_location"]
        period = PRESERVATION_PERIOD_MAP.get(row["preservation_period"], "ë¯¸í™•ì¸")
        if location in storage_data:
            storage_data[location][period] += row["total"]
            location_totals[location] += row["total"]
        total_sums[period] += row["total"]
        total_sums["í•©ê³„"] += row["total"]

    # ìƒì‚° ìœ í˜•ë³„ í†µê³„ ì´ˆê¸°í™”
    format_data = {
        "ì œ1ê¸°ë¡ê´€": {f: 0 for f in ["ë¬¸ì„œ", "ì¹´ë“œ", "ëŒ€ì¥", "ë„ë©´", "í•„ë¦„", "ì•¨ë²”", "í…Œì´í”„", "ê°„í–‰ë¬¼", "í–‰ì •ë°•ë¬¼"]},
        "ì œ2ê¸°ë¡ê´€": {f: 0 for f in ["ë¬¸ì„œ", "ì¹´ë“œ", "ëŒ€ì¥", "ë„ë©´", "í•„ë¦„", "ì•¨ë²”", "í…Œì´í”„", "ê°„í–‰ë¬¼", "í–‰ì •ë°•ë¬¼"]},
        "í–‰ì •ë°•ë¬¼ê´€": {f: 0 for f in ["ë¬¸ì„œ", "ì¹´ë“œ", "ëŒ€ì¥", "ë„ë©´", "í•„ë¦„", "ì•¨ë²”", "í…Œì´í”„", "ê°„í–‰ë¬¼", "í–‰ì •ë°•ë¬¼"]}
    }
    total_format_sums = {f: 0 for f in ["í•©ê³„", "ë¬¸ì„œ", "ì¹´ë“œ", "ëŒ€ì¥", "ë„ë©´", "í•„ë¦„", "ì•¨ë²”", "í…Œì´í”„", "ê°„í–‰ë¬¼", "í–‰ì •ë°•ë¬¼"]}
    location_format_totals = {"ì œ1ê¸°ë¡ê´€": 0, "ì œ2ê¸°ë¡ê´€": 0, "í–‰ì •ë°•ë¬¼ê´€": 0}

    cursor.execute("""
        SELECT storage_location, document_format, COUNT(*) AS total
        FROM documents
        WHERE storage_location IN ('ì œ1ê¸°ë¡ê´€', 'ì œ2ê¸°ë¡ê´€', 'í–‰ì •ë°•ë¬¼ê´€')
        GROUP BY storage_location, document_format
    """)
    for row in cursor.fetchall():
        location = row["storage_location"]
        format_type = row["document_format"]
        if location in format_data:
            format_data[location][format_type] += row["total"]
            location_format_totals[location] += row["total"]
        total_format_sums[format_type] += row["total"]
        total_format_sums["í•©ê³„"] += row["total"]

    cursor.close()
    conn.close()

    return render_template(
        'Main_Dashboard.html',
        storage_data=storage_data,
        total_sums=total_sums,
        format_data=format_data,
        total_format_sums=total_format_sums,
        location_totals=location_totals,
        location_format_totals=location_format_totals
    )

# âœ… ë¬¸ì„œ ê²€ìƒ‰/í™œìš© í˜ì´ì§€ (/searchë¡œ ë³€ê²½ë¨)
@app.route('/search')
def search():
    conn = get_db_connection()
    cursor = conn.cursor(dictionary=True)

    # ğŸ” ê²€ìƒ‰ í•„í„° ì²˜ë¦¬
    management_number = request.args.get('management_number', '')
    production_department = request.args.get('production_department', '')
    start_year = request.args.get('start_year')
    end_year = request.args.get('end_year')
    
    # Main_Dashboardì—ì„œ ì „ì†¡ëœ search_query ì²˜ë¦¬ â†’ ê¸°ë¡ë¬¼ì²  ì œëª© ê²€ìƒ‰
    folder_title = request.args.get('folder_title', '')
    search_query = request.args.get('search_query', '')
    if search_query:
        folder_title = search_query

    preservation_period = request.args.get('preservation_period', '')
    document_type = request.args.get('document_type', '')

    sort_by = request.args.get('sort_by', 'id')
    sort_order = request.args.get('sort_order', 'asc')

    # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
    per_page = int(request.args.get('per_page', 20))
    current_page = int(request.args.get('page', 1))
    offset = (current_page - 1) * per_page

    # SQL ì¿¼ë¦¬ ìƒì„± (í•„í„° ì ìš©)
    query = "SELECT * FROM documents WHERE 1=1"
    params = []
    if management_number:
        query += " AND management_number LIKE %s"
        params.append(f"%{management_number}%")
    if production_department:
        query += " AND production_department LIKE %s"
        params.append(f"%{production_department}%")
    if start_year and end_year:
        query += " AND production_year BETWEEN %s AND %s"
        params.extend([start_year, end_year])
    if folder_title:
        query += " AND folder_title LIKE %s"
        params.append(f"%{folder_title}%")
    if preservation_period:
        query += " AND preservation_period = %s"
        params.append(preservation_period)
    if document_type:
        query += " AND document_type = %s"
        params.append(document_type)
    query += f" ORDER BY {sort_by} {sort_order}"
    query += " LIMIT %s OFFSET %s"
    params.extend([per_page, offset])

    cursor.execute(query, params)
    documents = cursor.fetchall()

    for doc in documents:
        doc["preservation_period"] = PRESERVATION_PERIOD_MAP.get(doc["preservation_period"], "ë¯¸í™•ì¸")
        doc["retrieval_priority"] = RETRIEVAL_PRIORITY_MAP.get(doc["retrieval_priority"], "ë¯¸í™•ì¸")

    # ì „ì²´ í˜ì´ì§€ ìˆ˜ ê³„ì‚° (ê²€ìƒ‰ í•„í„° ì ìš©)
    count_query = "SELECT COUNT(*) AS total FROM documents WHERE 1=1"
    count_params = []
    if management_number:
        count_query += " AND management_number LIKE %s"
        count_params.append(f"%{management_number}%")
    if production_department:
        count_query += " AND production_department LIKE %s"
        count_params.append(f"%{production_department}%")
    if start_year and end_year:
        count_query += " AND production_year BETWEEN %s AND %s"
        count_params.extend([start_year, end_year])
    if folder_title:
        count_query += " AND folder_title LIKE %s"
        count_params.append(f"%{folder_title}%")
    if preservation_period:
        count_query += " AND preservation_period = %s"
        count_params.append(preservation_period)
    if document_type:
        count_query += " AND document_type = %s"
        count_params.append(document_type)

    cursor.execute(count_query, count_params)
    total_documents = cursor.fetchone()['total']
    total_pages = (total_documents // per_page) + (1 if total_documents % per_page != 0 else 0)

    cursor.close()
    conn.close()

    return render_template('search.html',
                           documents=documents,
                           per_page=per_page,
                           current_page=current_page,
                           total_pages=total_pages,
                           sort_by=sort_by,
                           sort_order=sort_order)

# CSV ë‹¤ìš´ë¡œë“œ (ì „ì²´ ë‹¤ìš´ë¡œë“œ)
@app.route('/download_csv_all')
def download_csv_all():
    conn = get_db_connection()
    cursor = conn.cursor(dictionary=True)
    cursor.execute("SELECT * FROM documents")
    documents = cursor.fetchall()

    # ë³´ì¡´ê¸°ê°„ ë° ë°˜ì¶œ ìˆœìœ„ ë³€í™˜
    for doc in documents:
        doc["preservation_period"] = PRESERVATION_PERIOD_MAP.get(doc["preservation_period"], "ë¯¸í™•ì¸")
        doc["retrieval_priority"] = RETRIEVAL_PRIORITY_MAP.get(doc["retrieval_priority"], "ë¯¸í™•ì¸")
    
    # ì›í•˜ëŠ” CSV í—¤ë”(ìˆœì„œ ë° ì´ë¦„)
    headers = [
        "ì—°ë²ˆ", "ê´€ë¦¬ë²ˆí˜¸", "í˜„ì¬ê¸°ê´€ëª…", "ìƒì‚°ê¸°ê´€ëª…", "ì„œê³ ìœ„ì¹˜", "ì„œê°€ìœ„ì¹˜", "ë°•ìŠ¤ë²ˆí˜¸",
        "ìƒì‚°ë…„ë„", "ì¢…ë£Œë…„ë„", "ë³´ì¡´ê¸°ê°„", "ê¸°ë¡ë¬¼êµ¬ë¶„", "ê¸°ë¡ë¬¼í˜•íƒœ", "ìˆ˜ëŸ‰",
        "ê¸°ë¡ë¬¼ì² ì œëª©", "ë¶€ê°€ì •ë³´", "ì´ì¤‘ë³´ì¡´ì—¬ë¶€", "í‰ê°€/íê¸°", "ìƒíƒœê²€ì‚¬", "ë°˜ì¶œìˆœìœ„", "ë¹„ê³ "
    ]
    
    # ê° í–‰ì—ì„œ created_at, updated_atì€ ì¶œë ¥í•˜ì§€ ì•Šê³ , ë‚˜ë¨¸ì§€ ê°’ì€ ë¬¸ì„œ dictì˜ í‚¤ì— ë”°ë¼ ê°€ì ¸ì˜¤ë©°, 
    # ì—†ëŠ” í‚¤ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    new_docs = []
    for idx, doc in enumerate(documents, start=1):
        new_doc = {
            "ì—°ë²ˆ": idx,
            "ê´€ë¦¬ë²ˆí˜¸": doc.get("management_number", ""),
            "í˜„ì¬ê¸°ê´€ëª…": doc.get("current_institution", ""),
            "ìƒì‚°ê¸°ê´€ëª…": doc.get("production_department", ""),
            "ì„œê³ ìœ„ì¹˜": doc.get("storage_location", ""),
            "ì„œê°€ìœ„ì¹˜": doc.get("shelf_location", ""),  # í•´ë‹¹ ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì¶œë ¥
            "ë°•ìŠ¤ë²ˆí˜¸": doc.get("box_number", ""),
            "ìƒì‚°ë…„ë„": doc.get("production_year", ""),
            "ì¢…ë£Œë…„ë„": doc.get("end_year", ""),
            "ë³´ì¡´ê¸°ê°„": doc.get("preservation_period", ""),
            "ê¸°ë¡ë¬¼êµ¬ë¶„": doc.get("document_type", ""),
            "ê¸°ë¡ë¬¼í˜•íƒœ": doc.get("document_format", ""),
            "ìˆ˜ëŸ‰": doc.get("quantity", ""),
            "ê¸°ë¡ë¬¼ì² ì œëª©": doc.get("folder_title", ""),
            "ë¶€ê°€ì •ë³´": doc.get("additional_info", ""),
            "ì´ì¤‘ë³´ì¡´ì—¬ë¶€": doc.get("dual_preservation", ""),
            "í‰ê°€/íê¸°": doc.get("evaluation_status", ""),
            "ìƒíƒœê²€ì‚¬": doc.get("status_check", ""),
            "ë°˜ì¶œìˆœìœ„": doc.get("retrieval_priority", ""),
            "ë¹„ê³ ": doc.get("notes", "")
        }
        new_docs.append(new_doc)
    
    # CSV ì‘ì„± (UTF-8 BOM ì¶”ê°€: 'utf-8-sig')
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=headers)
    writer.writeheader()
    writer.writerows(new_docs)
    output.seek(0)

    cursor.close()
    conn.close()

    return send_file(io.BytesIO(output.getvalue().encode('utf-8-sig')),
                     mimetype='text/csv',
                     as_attachment=True,
                     download_name='all_documents.csv')

# CSV ë‹¤ìš´ë¡œë“œ (ê²€ìƒ‰ ëª©ë¡ ë‹¤ìš´ë¡œë“œ)
@app.route('/download_csv_search')
def download_csv_search():
    conn = get_db_connection()
    cursor = conn.cursor(dictionary=True)

    management_number = request.args.get('management_number', '')
    production_department = request.args.get('production_department', '')
    start_year = request.args.get('start_year')
    end_year = request.args.get('end_year')
    
    folder_title = request.args.get('folder_title', '')
    search_query = request.args.get('search_query', '')
    if search_query:
        folder_title = search_query

    preservation_period = request.args.get('preservation_period', '')
    document_type = request.args.get('document_type', '')

    query = "SELECT * FROM documents WHERE 1=1"
    params = []
    if management_number:
        query += " AND management_number LIKE %s"
        params.append(f"%{management_number}%")
    if production_department:
        query += " AND production_department LIKE %s"
        params.append(f"%{production_department}%")
    if start_year and end_year:
        query += " AND production_year BETWEEN %s AND %s"
        params.extend([start_year, end_year])
    if folder_title:
        query += " AND folder_title LIKE %s"
        params.append(f"%{folder_title}%")
    if preservation_period:
        query += " AND preservation_period = %s"
        params.append(preservation_period)
    if document_type:
        query += " AND document_type = %s"
        params.append(document_type)

    cursor.execute(query, params)
    documents = cursor.fetchall()

    for doc in documents:
        doc["preservation_period"] = PRESERVATION_PERIOD_MAP.get(doc["preservation_period"], "ë¯¸í™•ì¸")
        doc["retrieval_priority"] = RETRIEVAL_PRIORITY_MAP.get(doc["retrieval_priority"], "ë¯¸í™•ì¸")
    
    headers = [
        "ì—°ë²ˆ", "ê´€ë¦¬ë²ˆí˜¸", "í˜„ì¬ê¸°ê´€ëª…", "ìƒì‚°ê¸°ê´€ëª…", "ì„œê³ ìœ„ì¹˜", "ì„œê°€ìœ„ì¹˜", "ë°•ìŠ¤ë²ˆí˜¸",
        "ìƒì‚°ë…„ë„", "ì¢…ë£Œë…„ë„", "ë³´ì¡´ê¸°ê°„", "ê¸°ë¡ë¬¼êµ¬ë¶„", "ê¸°ë¡ë¬¼í˜•íƒœ", "ìˆ˜ëŸ‰",
        "ê¸°ë¡ë¬¼ì² ì œëª©", "ë¶€ê°€ì •ë³´", "ì´ì¤‘ë³´ì¡´ì—¬ë¶€", "í‰ê°€/íê¸°", "ìƒíƒœê²€ì‚¬", "ë°˜ì¶œìˆœìœ„", "ë¹„ê³ "
    ]
    
    new_docs = []
    for idx, doc in enumerate(documents, start=1):
        new_doc = {
            "ì—°ë²ˆ": idx,
            "ê´€ë¦¬ë²ˆí˜¸": doc.get("management_number", ""),
            "í˜„ì¬ê¸°ê´€ëª…": doc.get("current_institution", ""),
            "ìƒì‚°ê¸°ê´€ëª…": doc.get("production_department", ""),
            "ì„œê³ ìœ„ì¹˜": doc.get("storage_location", ""),
            "ì„œê°€ìœ„ì¹˜": doc.get("shelf_location", ""),
            "ë°•ìŠ¤ë²ˆí˜¸": doc.get("box_number", ""),
            "ìƒì‚°ë…„ë„": doc.get("production_year", ""),
            "ì¢…ë£Œë…„ë„": doc.get("end_year", ""),
            "ë³´ì¡´ê¸°ê°„": doc.get("preservation_period", ""),
            "ê¸°ë¡ë¬¼êµ¬ë¶„": doc.get("document_type", ""),
            "ê¸°ë¡ë¬¼í˜•íƒœ": doc.get("document_format", ""),
            "ìˆ˜ëŸ‰": doc.get("quantity", ""),
            "ê¸°ë¡ë¬¼ì² ì œëª©": doc.get("folder_title", ""),
            "ë¶€ê°€ì •ë³´": doc.get("additional_info", ""),
            "ì´ì¤‘ë³´ì¡´ì—¬ë¶€": doc.get("dual_preservation", ""),
            "í‰ê°€/íê¸°": doc.get("evaluation_status", ""),
            "ìƒíƒœê²€ì‚¬": doc.get("status_check", ""),
            "ë°˜ì¶œìˆœìœ„": doc.get("retrieval_priority", ""),
            "ë¹„ê³ ": doc.get("notes", "")
        }
        new_docs.append(new_doc)
    
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=headers)
    writer.writeheader()
    writer.writerows(new_docs)
    output.seek(0)

    cursor.close()
    conn.close()

    return send_file(io.BytesIO(output.getvalue().encode('utf-8-sig')),
                     mimetype='text/csv',
                     as_attachment=True,
                     download_name='search_documents.csv')

if __name__ == '__main__':
    app.run(debug=True)
